{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f85995d8",
   "metadata": {},
   "source": [
    "# Evidence classification for boolean questions\n",
    "\n",
    "In this notebook, we look at the evidence classifation, which is a component in the Tydi pipeline which decides whether a boolean question should be answered `yes` or `no`.\n",
    "\n",
    "## Preliminaries\n",
    "We assume that the machine reading comprehension and the question type classifier components of the Tydi pipeline have already run, either through the integrated command line or the step-by-step process, both described [here](../../examples/boolqa/README.md)\n",
    "\n",
    "First some setup.  The classifier will obtain its input from the `eval_predictions.json` file of the previous step.\n",
    "Most of this setup is very similar to the setup for [mrc](../mrc/mrc.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eac1a725",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir=\"out\"\n",
    "input_file=\"/dccstor/jsmc-nmt-01/bool/expts/toolkit/b/b21/qtc/eval_predictions.json\"\n",
    "\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    HfArgumentParser,\n",
    "    Trainer,\n",
    "    TrainingArguments)\n",
    "from transformers.trainer_utils import set_seed\n",
    "from oneqa.boolqa.processors.postprocessors.nway import NWayClassifierPostProcessor\n",
    "from oneqa.boolqa.processors.preprocessors.default import NWayPreProcessor\n",
    "\n",
    "from examples.boolqa.mrc2dataset  import create_dataset_from_run_mrc_output, create_dataset_from_json_str\n",
    "import pandas as pd\n",
    "\n",
    "seed = 42\n",
    "set_seed(seed)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    do_train=False,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=1,\n",
    "    num_train_epochs=1,\n",
    "    evaluation_strategy='no',\n",
    "    learning_rate=4e-05,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.1,\n",
    "    save_steps=50000,\n",
    "    seed=seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0865c38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained('/dccstor/jsmc-nmt-01/bool/git/IOTA-boolean-challenge/model/evc-c5', num_labels=3)\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained('/dccstor/jsmc-nmt-01/bool/git/IOTA-boolean-challenge/model/evc-c5', use_fast=True)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('/dccstor/jsmc-nmt-01/bool/git/IOTA-boolean-challenge/model/evc-c5', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80cbf9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list=['no', 'no_answer', 'yes']\n",
    "\n",
    "postprocessor_class = NWayClassifierPostProcessor\n",
    "postprocessor = postprocessor_class(\n",
    "    k=10,       \n",
    "    drop_label=\"no_answer\",\n",
    "    label_list = label_list,\n",
    "    id_key='example_id',\n",
    "    output_label_prefix='boolean_answer'\n",
    ")\n",
    "\n",
    "preprocessor_class = NWayPreProcessor\n",
    "preprocessor = preprocessor_class(\n",
    "    sentence1_key='question',\n",
    "    sentence2_key='passage_answer_text',\n",
    "    tokenizer=tokenizer,\n",
    "    load_from_cache_file=False,\n",
    "    max_seq_len=500,\n",
    "    padding=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657250cb",
   "metadata": {},
   "source": [
    "## Inputs\n",
    "Here we create a dataset from the input file.  For illustrative purposes, we filter it to focus on the english questions that have been predicted to be boolean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90de5aba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45940bcb2d34f93bbbac4dc171e93df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30a0ae18828a4ea88d794b682e230b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['example_id', 'cls_score', 'start_logit', 'end_logit', 'span_answer', 'span_answer_score', 'start_index', 'end_index', 'passage_index', 'target_type_logits', 'span_answer_text', 'yes_no_answer', 'start_stdev', 'end_stdev', 'query_passage_similarity', 'normalized_span_answer_score', 'confidence_score', 'question', 'language', 'passage_answer_text', 'order', 'rank', 'question_type_pred', 'question_type_scores', 'question_type_conf'],\n",
       "    num_rows: 112\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples=create_dataset_from_run_mrc_output(input_file, unpack=False)\n",
    "examples=examples.filter(lambda x:x['language']=='english' and x['question_type_pred']=='boolean')\n",
    "eval_examples, eval_dataset = preprocessor.process_eval(examples)\n",
    "eval_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb93e6a",
   "metadata": {},
   "source": [
    "## Do the predictions.\n",
    "As in mrc, the trainer class instance runs the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b322b0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: passage_answer_text, question, language, example_id. If passage_answer_text, question, language, example_id are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 112\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:51]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer( \n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=None,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=None, #compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=None,\n",
    ")\n",
    "predictions = trainer.predict(eval_dataset, metric_key_prefix=\"predict\").predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceac1a87",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "\n",
    "The pretrained model we provide is actually as ternary model - it predictions `no`, `no_answer`, or `yes`.  The `no_answer` is discarded for pipelines that end with an actual tydi evaluation, since the tydi evaluation script selects the score threshold that distinguishes answerable and unanswerable questions.  However, other applications may want to make use of this category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d265ec29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.042522</td>\n",
       "      <td>3.994114</td>\n",
       "      <td>1.586288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.808026</td>\n",
       "      <td>0.210620</td>\n",
       "      <td>5.496010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.695564</td>\n",
       "      <td>-1.510027</td>\n",
       "      <td>-3.645893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.671103</td>\n",
       "      <td>-3.745991</td>\n",
       "      <td>2.243662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.872703</td>\n",
       "      <td>6.205071</td>\n",
       "      <td>-1.955134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0 -5.042522  3.994114  1.586288\n",
       "1 -5.808026  0.210620  5.496010\n",
       "2  5.695564 -1.510027 -3.645893\n",
       "3  0.671103 -3.745991  2.243662\n",
       "4 -3.872703  6.205071 -1.955134"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_records(predictions[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4af8b7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in process_references_and_predictions\n",
      "Dataset({\n",
      "    features: ['example_id', 'cls_score', 'start_logit', 'end_logit', 'span_answer', 'span_answer_score', 'start_index', 'end_index', 'passage_index', 'target_type_logits', 'span_answer_text', 'yes_no_answer', 'start_stdev', 'end_stdev', 'query_passage_similarity', 'normalized_span_answer_score', 'confidence_score', 'question', 'language', 'passage_answer_text', 'order', 'rank', 'question_type_pred', 'question_type_scores', 'question_type_conf', 'boolean_answer_pred', 'boolean_answer_scores', 'boolean_answer_conf'],\n",
      "    num_rows: 112\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "eval_preds = postprocessor.process_references_and_predictions(eval_examples, eval_dataset, predictions)\n",
    "eval_preds_ds = create_dataset_from_json_str(eval_preds.predictions, False)\n",
    "print(eval_preds_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab9638d",
   "metadata": {},
   "source": [
    "## Questions and answers\n",
    "\n",
    "Here we display some questions that have been identified as boolean, and their predicted answers, based on the system output of the MRC system.  A weakness in the TydiQA dataset is that most (85%) of the boolean questions have an answer of `yes` - apparently the question writers wrote questions seeking confirmations of what they already knew or suspected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3338975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcfc46abe05c40b8b4c0b46ade4b9eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>question</th>\n",
       "      <th>passage_answer_text</th>\n",
       "      <th>boolean_answer_pred</th>\n",
       "      <th>boolean_answer_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>98f388c7-979b-4e7b-9ed3-c8f5d3c0d413</td>\n",
       "      <td>Does an animal with vertebrae have to be a chordate?</td>\n",
       "      <td>The Chordata and Ambulacraria together form the superphylum Deuterostomia. Chordates are divided into three subphyla: Vertebrata (fish, amphibians, reptiles, birds, and mammals); Tunicata (salps and sea squirts); and Cephalochordata (which includes lancelets). There are also extinct taxa such as the...</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'no': -0.42267709970474243, 'no_answer': -3.2861926555633545, 'yes': 3.6643331050872803}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>4378e5d8-fee1-4fee-be66-f2b0fe5f61e9</td>\n",
       "      <td>Does California get snow?</td>\n",
       "      <td>The high mountains, including the Sierra Nevada, the Cascade Range, and the Klamath Mountains, have a mountain climate with snow in winter and mild to moderate heat in summer. Ski resorts at Lake Tahoe, Mammoth Lakes, and Mount Shasta routinely receive over 10 feet (3.0m) of snow in a season, and so...</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'no': -5.855449676513672, 'no_answer': -0.5776659846305847, 'yes': 5.964153289794922}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3a8ee247-2976-43cf-8a04-8cd7970ee323</td>\n",
       "      <td>Does the Magellanic Cloud system have a super massive black hole?</td>\n",
       "      <td>The Large Magellanic Cloud and its neighbour and relative, the Small Magellanic Cloud, are conspicuous objects in the southern hemisphere, looking like separated pieces of the Milky Way to the naked eye. Roughly 21° apart in the night sky, the true distance between them is roughly 75,000 light-years...</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'no': -3.8727025985717773, 'no_answer': 6.205071449279785, 'yes': -1.955134391784668}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>466eb35c-762b-4d75-84d1-b3434b512555</td>\n",
       "      <td>Is the great horned owl endangered?</td>\n",
       "      <td>Frequently, the species were denominated a pest due to the perceived threat it posed to domestic fowl and potentially small game. The first genuine nature conservationists, while campaigning against the \"Extermination Being Waged Against the Hawks and Owls\", continued to advocate the destruction of ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'no': -5.3778839111328125, 'no_answer': -1.124822735786438, 'yes': 6.441001892089844}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3a1cd42c-7bfe-47b5-8288-ac7df0213b8d</td>\n",
       "      <td>Is the Mauser C96 produced today?</td>\n",
       "      <td>The Mauser C96 (Construktion 96)[4] is a semi-automatic pistol that was originally produced by German arms manufacturer Mauser from 1896 to 1937.[5] Unlicensed copies of the gun were also manufactured in Spain and China in the first half of the 20th century.[5][6]...</td>\n",
       "      <td>no</td>\n",
       "      <td>{'no': 4.936239719390869, 'no_answer': 0.35698825120925903, 'yes': -4.551218032836914}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>d9d4a59f-01ea-4c67-8f9c-58c679ab6412</td>\n",
       "      <td>Can the central nervous system heal itself?</td>\n",
       "      <td>Nervous system injuries affect over 90,000 people every year.[2] It is estimated that spinal cord injuries alone affect 10,000 each year.[3] As a result of this high incidence of neurological injuries, nerve regeneration and repair, a subfield of neural tissue engineering, is becoming a rapidly grow...</td>\n",
       "      <td>no</td>\n",
       "      <td>{'no': 1.9971495866775513, 'no_answer': -1.7380597591400146, 'yes': -0.20945601165294647}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>dbcd04df-cb7b-47e0-8ae0-2f8d9f294061</td>\n",
       "      <td>Is Daydream Software still an active company?</td>\n",
       "      <td>The Israeli company Waze Mobile developed the Waze software. Ehud Shabtai, Amir Shinar and Uri Levine founded the company. Two Israeli venture capital firms, Magma and Vertex, and an early-stage American venture capital firm, Bluerun Ventures, provided funding. Google acquired Waze Mobile in 2013....</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'no': -4.1507720947265625, 'no_answer': 6.917901992797852, 'yes': -2.0596728324890137}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>41471b45-8b0f-4a83-a91d-19f388a544cb</td>\n",
       "      <td>Is Cantonese written the same as Mandarin?</td>\n",
       "      <td>Written Cantonese is the written form of Cantonese, the most complete written form of Chinese after that for Mandarin Chinese and Classical Chinese. Written Chinese was originally developed for Classical Chinese, and was the main literary language of China until the 19th century.  Written vernacular...</td>\n",
       "      <td>no</td>\n",
       "      <td>{'no': 4.523313522338867, 'no_answer': -5.283786773681641, 'yes': 0.3928956389427185}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>70b2ef92-450b-4074-978f-01204487ea27</td>\n",
       "      <td>Does the KGB still exist?</td>\n",
       "      <td>The agency was a military service governed by army laws and regulations, in the same fashion as the Soviet Army or MVD Internal Troops. While most of the KGB archives remain classified, two online documentary sources are available.[1][2] Its main functions were foreign intelligence, counter-intellig...</td>\n",
       "      <td>no</td>\n",
       "      <td>{'no': 2.16046142578125, 'no_answer': 0.9643279314041138, 'yes': -2.6827592849731445}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>94276bb1-d708-4abc-8da8-616877e9996a</td>\n",
       "      <td>Is there a cure for juvenile rheumatoid arthritis?</td>\n",
       "      <td>JIA is best treated by a multidisciplinary team. The major emphasis of treatment for JIA is to help the child regain normal level of physical and social activities. This is accomplished with the use of physical therapy, pain management strategies, and social support.[28] Another emphasis of treatmen...</td>\n",
       "      <td>no</td>\n",
       "      <td>{'no': 5.612573623657227, 'no_answer': -0.8928341269493103, 'yes': -3.8825323581695557}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from examples.boolqa.mrc2dataset  import create_dataset_from_run_mrc_output\n",
    "\n",
    "from datasets import ClassLabel, Sequence\n",
    "from numpy.random import permutation\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Based on https://github.com/huggingface/notebooks/blob/main/examples/question_answering.ipynb\n",
    "def show_balanced_examples(dataset, perm, groups, nrows, maxchars, cols):\n",
    "    df = pd.DataFrame(dataset)\n",
    "    dfp = df.iloc[perm] # shuffle\n",
    "    dfg = dfp.groupby(groups)\n",
    "    df_todisplay = dfg.head(nrows)[cols]\n",
    "    if 'passage_answer_text' in cols:\n",
    "        df_todisplay['passage_answer_text'] = df_todisplay['passage_answer_text'].str.slice(0,maxchars) + '...'\n",
    "    display(HTML(df_todisplay.to_html()))\n",
    "    \n",
    "    \n",
    "\n",
    "english_boolean_eval_examples = eval_preds_ds.filter(lambda x:x['language']=='english' and x['question_type_pred']=='boolean')\n",
    "random_idxs = permutation(len(english_boolean_eval_examples))\n",
    "cols=['example_id','question','passage_answer_text', 'boolean_answer_pred', 'boolean_answer_scores']\n",
    "show_balanced_examples(english_boolean_eval_examples, random_idxs, 'boolean_answer_pred', 5, 300, cols)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
