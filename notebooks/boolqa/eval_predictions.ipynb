{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d58979d",
   "metadata": {},
   "source": [
    "# TydiQA - support for boolean questions\n",
    "\n",
    "Here we assume that you have used `run_mrc.py` with the `--do_boolean` option to decode the TydiQA dataset with full support for boolean questions.  See top-level README.md. There are four stages in the process:\n",
    "\n",
    "1. MRC (machine reading comprehension) - given a question and and answer, find a representative span that may contain a short answer.  This is analyzed in detail in the `tydiqa.ipynb`\n",
    "2. QTC (question type classifier) - given the question, decide if it is `boolean` or `short_answer`\n",
    "3. EVC (evidence classifier) - given a question and a short answer span, decide the short answer span supports `yes` or `no`.  This is analyzed in more detail in `evc.ipynb`.\n",
    "4. Score normalization - span scores may have different dynamic ranges according as whether the question is `boolean` or `short_anwer`.  Normalize them uniformally to $[0,1]$\n",
    "\n",
    "In this notebook, we will show what happened internally in each step of the operation by looking at intermediate files from the experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e2ffcf",
   "metadata": {},
   "source": [
    "# Intermediate files\n",
    "\n",
    "We will load some output/intermediate files from a recent experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b166b1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "base='/dccstor/jsmc-nmt-01/bool/expts/toolkit/b/b21'\n",
    "mrc_file=f'{base}/mrc/eval_predictions.json'\n",
    "qtc_file=f'{base}/qtc/eval_predictions.json'\n",
    "evc_file=f'{base}/evc/eval_predictions.json'\n",
    "out_file=f'{base}/eval_predictions_merge.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c70fdd",
   "metadata": {},
   "source": [
    "# Display helper\n",
    "\n",
    "These file have many fields - to display them better we use a helper routine to convert to dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75834e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.boolqa.mrc2dataset  import create_dataset_from_run_mrc_output\n",
    "\n",
    "from datasets import ClassLabel, Sequence\n",
    "from numpy.random import permutation\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Based on https://github.com/huggingface/notebooks/blob/main/examples/question_answering.ipynb\n",
    "def show_balanced_examples(dataset, perm, groups, nrows, maxchars, cols):\n",
    "    df = pd.DataFrame(dataset)\n",
    "    dfp = df.iloc[perm] # shuffle\n",
    "    dfg = dfp.groupby(groups)\n",
    "    df_todisplay = dfg.head(nrows)[cols]\n",
    "    if 'passage_answer_text' in cols:\n",
    "        df_todisplay['passage_answer_text'] = df_todisplay['passage_answer_text'].str.slice(0,maxchars) + '...'\n",
    "    display(HTML(df_todisplay.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1550c7d6",
   "metadata": {},
   "source": [
    "# Samples of MRC output\n",
    "\n",
    "Here we show `question`'s and predicted answer `span_answer_text` for the random examples.  This is at the initial stage of question answering - a purely extractive system.  The confidence in the span answer is given by `span_answer_score`, which is a function of `start_logit`, `end_logit`, and `target_type_logits`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07ecb031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>question</th>\n",
       "      <th>span_answer_text</th>\n",
       "      <th>language</th>\n",
       "      <th>span_answer_score</th>\n",
       "      <th>start_logit</th>\n",
       "      <th>end_logit</th>\n",
       "      <th>target_type_logits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17565</th>\n",
       "      <td>2663bd8c-f3f3-42c7-824e-f7b29c1ac899</td>\n",
       "      <td>ఆర్మేనియా దేశంలో అతిపెద్ద ఆర్ట్ మ్యూజియం ఏది?</td>\n",
       "      <td>అర్మేనియన్ ఎస్ఎస్ఆర్ యొక్క మ్యూజియం ఆఫ్ ఆర్ట్</td>\n",
       "      <td>telugu</td>\n",
       "      <td>0.780762</td>\n",
       "      <td>1.149414</td>\n",
       "      <td>1.539062</td>\n",
       "      <td>[3.9140625, 3.685546875, 0.86474609375, -5.7109375, -6.61328125]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16185</th>\n",
       "      <td>35ff8439-ae6c-4d78-8eb0-fc056a259818</td>\n",
       "      <td>How many people work for the British East India Company?</td>\n",
       "      <td>90</td>\n",
       "      <td>english</td>\n",
       "      <td>3.193359</td>\n",
       "      <td>2.351562</td>\n",
       "      <td>2.716797</td>\n",
       "      <td>[4.21484375, 5.390625, 0.1146240234375, -6.12890625, -7.0234375]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911</th>\n",
       "      <td>30c1c548-8b09-41ff-8f6c-b55d4c312f8a</td>\n",
       "      <td>Mihin kieleen hollannin kieli pohjautuu?</td>\n",
       "      <td>Saksa</td>\n",
       "      <td>finnish</td>\n",
       "      <td>4.063965</td>\n",
       "      <td>2.615234</td>\n",
       "      <td>2.996094</td>\n",
       "      <td>[2.328125, 4.67578125, 2.021484375, -5.2109375, -6.18359375]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6524</th>\n",
       "      <td>b494e3d0-8e9a-494f-a66c-4fbff541244d</td>\n",
       "      <td>Apa faktor utama Misogini terjadi?</td>\n",
       "      <td>laki-laki sebagai pemegang kekuasaan utama dan mendominasi dalam peran kepemimpinan politik, otoritas moral, hak sosial dan penguasaan properti</td>\n",
       "      <td>indonesian</td>\n",
       "      <td>-3.078247</td>\n",
       "      <td>-1.200195</td>\n",
       "      <td>-0.358643</td>\n",
       "      <td>[6.15234375, 3.23828125, -1.236328125, -6.36328125, -6.9296875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>1c7400e5-03a8-438a-b9dc-b69d753b0d8d</td>\n",
       "      <td>Je,Johann Bayer alikuwa na mke?</td>\n",
       "      <td>Mjerumani Johann Bayer alibuni mfumo wa kutaja nyota ambao kimsingi unaendelea kutumiwa hadi leo[1].</td>\n",
       "      <td>swahili</td>\n",
       "      <td>-5.178467</td>\n",
       "      <td>-5.015625</td>\n",
       "      <td>-0.548340</td>\n",
       "      <td>[5.97265625, 2.16015625, -1.9482421875, -5.546875, -5.8515625]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4373</th>\n",
       "      <td>aca5c5e9-8ec7-4c5c-a2bd-7c31a045a5d2</td>\n",
       "      <td>อักษรย่อของ โรงเรียนราชวิทยาลัย คืออะไร?</td>\n",
       "      <td>ภ.ป.ร</td>\n",
       "      <td>thai</td>\n",
       "      <td>3.794922</td>\n",
       "      <td>2.562500</td>\n",
       "      <td>3.171875</td>\n",
       "      <td>[2.892578125, 4.70703125, 1.771484375, -5.54296875, -6.59765625]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17166</th>\n",
       "      <td>28daee78-2ded-4b5d-8ea4-163828d2e72b</td>\n",
       "      <td>ডালিয়া গ্রিবাউস্কাইটে কোন রাজনৈতিক দলের নেতা ছিলেন ?</td>\n",
       "      <td>কনজারভেটিভ পার্টি</td>\n",
       "      <td>bengali</td>\n",
       "      <td>4.260254</td>\n",
       "      <td>2.689453</td>\n",
       "      <td>2.818359</td>\n",
       "      <td>[2.80078125, 4.9921875, 1.8212890625, -5.578125, -6.59375]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14858</th>\n",
       "      <td>4ec268c2-b81a-4a44-a149-8eacf1358dd2</td>\n",
       "      <td>Где находится Центральный аппарат Министе́рства энергетики и электрификации СССР?</td>\n",
       "      <td>Москва, 25 Октября, д. 17</td>\n",
       "      <td>russian</td>\n",
       "      <td>11.627930</td>\n",
       "      <td>4.953125</td>\n",
       "      <td>4.945312</td>\n",
       "      <td>[0.1588134765625, 6.8984375, -0.376708984375, -2.958984375, -3.59765625]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>4c259304-c44a-4607-8f1e-19e653bd8ae4</td>\n",
       "      <td>ما هي البطالة الإحتكاكية؟</td>\n",
       "      <td>نوع من أنواع البطالة المؤقتة (لفترة زمنية قصيرة).</td>\n",
       "      <td>arabic</td>\n",
       "      <td>11.148438</td>\n",
       "      <td>4.453125</td>\n",
       "      <td>3.945312</td>\n",
       "      <td>[0.1854248046875, 6.91015625, -0.320556640625, -3.013671875, -3.595703125]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7464</th>\n",
       "      <td>5b24d244-aec1-46fd-a9c5-8e93cdd71cb6</td>\n",
       "      <td>2019년 까지 노벨상을 받은 과학자는 몇 명인가?</td>\n",
       "      <td>2018년 시점에서 수상자가 없음</td>\n",
       "      <td>korean</td>\n",
       "      <td>-0.830688</td>\n",
       "      <td>0.426514</td>\n",
       "      <td>1.812500</td>\n",
       "      <td>[4.91796875, 3.201171875, -0.4189453125, -5.875, -6.5703125]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4009</th>\n",
       "      <td>5f558221-f153-43bc-99e4-3886e2f5cf48</td>\n",
       "      <td>ボウリングの起源はいつ</td>\n",
       "      <td>紀元前5000年</td>\n",
       "      <td>japanese</td>\n",
       "      <td>8.574341</td>\n",
       "      <td>4.316406</td>\n",
       "      <td>4.707031</td>\n",
       "      <td>[1.857421875, 7.08984375, -0.148193359375, -4.78515625, -5.58984375]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_examples=create_dataset_from_run_mrc_output(mrc_file, unpack=False)\n",
    "random_idxs = permutation(len(eval_examples))\n",
    "\n",
    "cols=['example_id','question','span_answer_text','language', 'span_answer_score', 'start_logit', 'end_logit', 'target_type_logits']\n",
    "show_balanced_examples(eval_examples, random_idxs, 'language', 1, 100, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6a891b",
   "metadata": {},
   "source": [
    "# Samples of QTC output\n",
    "\n",
    "Three fields have been added: `question_type_pred` which is `YN` if the question is a boolean question, and `NONE` if the question is not boolean - typically factoid in this dataset.\n",
    "The other field `question_type_scores` contains the classifier scores (logits) for each class.  The final field, `question_type_conf` contains score of the selected class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23c748f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b1234abe174495d96fefdce8da4362e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>question</th>\n",
       "      <th>question_type_pred</th>\n",
       "      <th>question_type_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>dc4db7c8-9df6-4ab3-b154-bad9be194507</td>\n",
       "      <td>What is the largest recorded tsunami?</td>\n",
       "      <td>short_answer</td>\n",
       "      <td>{'boolean': -2.997452974319458, 'short_answer': 3.781531810760498}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>233a6264-edd4-4e76-a497-1be970da22bb</td>\n",
       "      <td>Is Pippin the Hunchback dead?</td>\n",
       "      <td>boolean</td>\n",
       "      <td>{'boolean': 3.4151370525360107, 'short_answer': -4.333227634429932}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>d2ae656b-dcda-49dd-986c-429a65bee44d</td>\n",
       "      <td>When was the surrender of Japan signed?</td>\n",
       "      <td>short_answer</td>\n",
       "      <td>{'boolean': -2.997558116912842, 'short_answer': 3.780714511871338}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>3c915c7a-0d44-4cdd-b39e-ff9060af1734</td>\n",
       "      <td>How much room does it take to keep a horse?</td>\n",
       "      <td>short_answer</td>\n",
       "      <td>{'boolean': -2.9940197467803955, 'short_answer': 3.7767441272735596}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>806890de-5814-4e2c-98c2-df8c37a47482</td>\n",
       "      <td>How many copies of Blood Omen: Legacy of Kain were sold?</td>\n",
       "      <td>short_answer</td>\n",
       "      <td>{'boolean': -2.995069742202759, 'short_answer': 3.7774362564086914}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>9db3a975-84ec-4c1b-8c56-c8941fcf5c10</td>\n",
       "      <td>What is the density of a diamond?</td>\n",
       "      <td>short_answer</td>\n",
       "      <td>{'boolean': -2.997520923614502, 'short_answer': 3.7809488773345947}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>c08a47e2-f943-41e3-ba27-9a274e4268d0</td>\n",
       "      <td>Did Austria ever become part of Prussia?</td>\n",
       "      <td>boolean</td>\n",
       "      <td>{'boolean': 3.4198384284973145, 'short_answer': -4.328428268432617}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>3fb65db7-c0b3-47be-87be-112df1b32cb7</td>\n",
       "      <td>Is there tomato in mutter paneer?</td>\n",
       "      <td>boolean</td>\n",
       "      <td>{'boolean': 3.4148740768432617, 'short_answer': -4.333624362945557}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>8b9b5c68-4e76-43ef-bd7c-e2e34b051178</td>\n",
       "      <td>Is there a championship for stock car racing?</td>\n",
       "      <td>boolean</td>\n",
       "      <td>{'boolean': 3.4153878688812256, 'short_answer': -4.333537578582764}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>70b2ef92-450b-4074-978f-01204487ea27</td>\n",
       "      <td>Does the KGB still exist?</td>\n",
       "      <td>boolean</td>\n",
       "      <td>{'boolean': 3.4159293174743652, 'short_answer': -4.333240509033203}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_examples=create_dataset_from_run_mrc_output(qtc_file, unpack=False)\n",
    "english_eval_examples = eval_examples.filter(lambda x:x['language']=='english')\n",
    "random_idxs = permutation(len(english_eval_examples))\n",
    "cols=['example_id','question','question_type_pred', 'question_type_scores']\n",
    "show_balanced_examples(english_eval_examples, random_idxs, 'question_type_pred', 5, 100, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c49dbb3",
   "metadata": {},
   "source": [
    "# Samples of EVC output \n",
    "As above this classifier adds three new fields.  `boolean_answer_pred` is `True` if the predicted answer to a boolean question is positive/yes, `False` if the answer is negative/no, and `NONE` if there is no support for either answer in the context.  `boolean_answer_scores` provides the scores (logits) of each class, and `boolean_answer_conf` is the score of the selected class.\n",
    "We select the English questions from the dev set (they are not scored by tydi_eval.py), which have a higher fraction of boolean questions.  The boolean questions in the tydi dataset are overwhelmingly biased towards having a `yes` rather than a `no`  as the answer.  We suspect that the question writers were attempting to confirm existing knowledge.\n",
    "Note that the answer classifier runs even on the short answer questions in order to simplify merging - a real deployed system would run the answer classifier only on questions that are predicted to be boolean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbfa3a7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f81a4d284a24db5a5710776a247af05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>question</th>\n",
       "      <th>passage_answer_text</th>\n",
       "      <th>boolean_answer_pred</th>\n",
       "      <th>boolean_answer_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>66c22597-8287-4fe5-8358-767bc4d936d4</td>\n",
       "      <td>Does Donna Troy have any superpowers?</td>\n",
       "      <td>In her pre-Crisis origin, Donna was granted those powers by the Amazon's Purple Ray, and these powers increased as she grew older. She also wielded a lasso of her own, but it apparently had no magical properties like Diana's Lasso of Truth, aside from being infinite in length and virtually indestruc...</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'no': -5.461025714874268, 'no_answer': -1.1184296607971191, 'yes': 6.664615631103516}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>41471b45-8b0f-4a83-a91d-19f388a544cb</td>\n",
       "      <td>Is Cantonese written the same as Mandarin?</td>\n",
       "      <td>Written Cantonese is the written form of Cantonese, the most complete written form of Chinese after that for Mandarin Chinese and Classical Chinese. Written Chinese was originally developed for Classical Chinese, and was the main literary language of China until the 19th century.  Written vernacular...</td>\n",
       "      <td>no</td>\n",
       "      <td>{'no': 4.523262023925781, 'no_answer': -5.28380012512207, 'yes': 0.39295539259910583}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0323472e-56b8-4385-ad74-2c2786ca87f5</td>\n",
       "      <td>Has Romania been an any major war?</td>\n",
       "      <td>The Romanian United Principalities did not participate in any wars....</td>\n",
       "      <td>no</td>\n",
       "      <td>{'no': 6.055264949798584, 'no_answer': -3.06253981590271, 'yes': -2.9737067222595215}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>c98ff20e-4e9f-4cc0-ae0e-4414cce3742a</td>\n",
       "      <td>Can you eat a black wildebeest?</td>\n",
       "      <td>Wildebeest provide several useful animal products. The hide makes good-quality leather and the flesh is coarse, dry and rather hard.[13] Wildebeest are killed for food, especially to make biltong in Southern Africa. This dried game meat is a delicacy and an important food item in Africa.[25] The mea...</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'no': -5.193129539489746, 'no_answer': -1.4364780187606812, 'yes': 6.304743766784668}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2030a582-ebd2-45bf-9690-fe46007c71ee</td>\n",
       "      <td>Does Frankfurt have a regional dish?</td>\n",
       "      <td>Handkäse (pronounced[ˈhantkɛːzə]; literally: \"hand cheese\") is a German regional sour milk cheese (similar to Harzer) and is a culinary speciality of Frankfurt am Main, Offenbach am Main, Darmstadt, Langen, and other parts of southern Hesse. It gets its name from the traditional way of producing it:...</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'no': -5.1389312744140625, 'no_answer': -1.3864237070083618, 'yes': 6.278087615966797}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bf0d744a-caf5-4df1-83ee-9de58ccdb071</td>\n",
       "      <td>Does Japan get snow?</td>\n",
       "      <td>The most recent record snows were brought by the blizzards of December 2005–February 2006, when well over 3m (4.5m in one part of Aomori Prefecture) of snow accumulated in many rural areas, and anywhere from  46cm (Tottori) to nearly 1.5m (Aomori) piled up even in several major cities....</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'no': -5.7697601318359375, 'no_answer': -0.8454253077507019, 'yes': 5.994254112243652}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>3010ea68-96d7-4893-95ab-5f05c566071c</td>\n",
       "      <td>Did the Tudor family participate in the War of Roses?</td>\n",
       "      <td>The Wars of the Roses were a series of English civil wars for control of the throne of England fought between supporters of two rival branches of the royal House of Plantagenet: the House of Lancaster, associated with a red rose, and the House of York, whose symbol was a white rose. Eventually, the ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'no': -4.764363765716553, 'no_answer': 4.752935409545898, 'yes': 0.5020203590393066}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>652fd953-2522-45de-af19-7ec8f2a98183</td>\n",
       "      <td>Is St Joseph's a private school?</td>\n",
       "      <td>The Toronto Catholic District School Board bought the College School property from the Sisters of St. Joseph in December 2007....</td>\n",
       "      <td>no</td>\n",
       "      <td>{'no': 4.562924861907959, 'no_answer': -0.22298750281333923, 'yes': -4.307789325714111}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>94276bb1-d708-4abc-8da8-616877e9996a</td>\n",
       "      <td>Is there a cure for juvenile rheumatoid arthritis?</td>\n",
       "      <td>JIA is best treated by a multidisciplinary team. The major emphasis of treatment for JIA is to help the child regain normal level of physical and social activities. This is accomplished with the use of physical therapy, pain management strategies, and social support.[28] Another emphasis of treatmen...</td>\n",
       "      <td>no</td>\n",
       "      <td>{'no': 5.612574577331543, 'no_answer': -0.8928354382514954, 'yes': -3.8825314044952393}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>282e7d03-4fcc-4a26-b8cf-6a0def4c10e4</td>\n",
       "      <td>Was Spain part of the Allied Forces?</td>\n",
       "      <td>The Spanish State under Francisco Franco did not officially join the Axis Powers during World War II, although Franco wrote to Hitler offering to join the war on 19 June 1940. Franco's regime supplied Germany with the Blue Division to fight specifically on the Eastern Front against the Soviet Union,...</td>\n",
       "      <td>no</td>\n",
       "      <td>{'no': 5.607361793518066, 'no_answer': -1.9422791004180908, 'yes': -3.5038347244262695}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_examples=create_dataset_from_run_mrc_output(evc_file, unpack=False)\n",
    "english_boolean_eval_examples = eval_examples.filter(lambda x:x['language']=='english' and x['question_type_pred']=='boolean')\n",
    "random_idxs = permutation(len(english_boolean_eval_examples))\n",
    "cols=['example_id','question','passage_answer_text', 'boolean_answer_pred', 'boolean_answer_scores']\n",
    "show_balanced_examples(english_boolean_eval_examples, random_idxs, 'boolean_answer_pred', 5, 300, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4a2201",
   "metadata": {},
   "source": [
    "# Final output\n",
    "\n",
    "The final output file is in a format suitable for the tydi evalutation script and contains no textual information.  The `confidence_score` is normalized to `[0,1]` by the score normalizer based the confidence score of the original mrc output, and the prediction of the question type classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "362efbf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>start_position</th>\n",
       "      <th>end_position</th>\n",
       "      <th>passage_index</th>\n",
       "      <th>yes_no_answer</th>\n",
       "      <th>confidence_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b9eba742-f264-4fec-92d0-9b8de5ad0bd7</td>\n",
       "      <td>986</td>\n",
       "      <td>1020</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.653616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a71fe9c2-e518-4923-bced-4fe99cc7ff44</td>\n",
       "      <td>371</td>\n",
       "      <td>388</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2dcec21a-60bb-4ee9-85bc-6066f1ac6de3</td>\n",
       "      <td>14805</td>\n",
       "      <td>14807</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84603ec2-1637-4b13-96f5-5ef701c74a12</td>\n",
       "      <td>5993</td>\n",
       "      <td>6010</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.308387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a32fd17a-736a-4299-a543-bc26d68fa8dc</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.197467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18665</th>\n",
       "      <td>2634d4e7-99a7-40ad-aafa-829dc1270e3d</td>\n",
       "      <td>2563</td>\n",
       "      <td>2586</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.659538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18666</th>\n",
       "      <td>36227a7f-f387-4d98-99b4-0ba522db3746</td>\n",
       "      <td>183</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18667</th>\n",
       "      <td>17c7494a-c30e-4c0b-a0ba-b4c0487edf05</td>\n",
       "      <td>1483</td>\n",
       "      <td>1585</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.193370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18668</th>\n",
       "      <td>1e37c005-6d6b-436f-a97c-8dabc2c67704</td>\n",
       "      <td>723</td>\n",
       "      <td>731</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18669</th>\n",
       "      <td>292b3778-f492-484c-ac41-997cf62e39e1</td>\n",
       "      <td>1455</td>\n",
       "      <td>1461</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.220289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18670 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 example_id  start_position  end_position  \\\n",
       "0      b9eba742-f264-4fec-92d0-9b8de5ad0bd7             986          1020   \n",
       "1      a71fe9c2-e518-4923-bced-4fe99cc7ff44             371           388   \n",
       "2      2dcec21a-60bb-4ee9-85bc-6066f1ac6de3           14805         14807   \n",
       "3      84603ec2-1637-4b13-96f5-5ef701c74a12            5993          6010   \n",
       "4      a32fd17a-736a-4299-a543-bc26d68fa8dc               1            22   \n",
       "...                                     ...             ...           ...   \n",
       "18665  2634d4e7-99a7-40ad-aafa-829dc1270e3d            2563          2586   \n",
       "18666  36227a7f-f387-4d98-99b4-0ba522db3746             183           192   \n",
       "18667  17c7494a-c30e-4c0b-a0ba-b4c0487edf05            1483          1585   \n",
       "18668  1e37c005-6d6b-436f-a97c-8dabc2c67704             723           731   \n",
       "18669  292b3778-f492-484c-ac41-997cf62e39e1            1455          1461   \n",
       "\n",
       "       passage_index  yes_no_answer  confidence_score  \n",
       "0                  2              0          0.653616  \n",
       "1                  1              0          0.020314  \n",
       "2                 27              0          0.038392  \n",
       "3                 12              0          0.308387  \n",
       "4                  0              0          0.197467  \n",
       "...              ...            ...               ...  \n",
       "18665              5              0          0.659538  \n",
       "18666              0              0          0.001075  \n",
       "18667              4              0          0.193370  \n",
       "18668              3              0          0.004098  \n",
       "18669              3              0          0.220289  \n",
       "\n",
       "[18670 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1444f38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
