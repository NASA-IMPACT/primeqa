{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQuAD 1.1\n",
    "\n",
    "In this notebook, we will see how to fine-tune and evaluate a model on the SQuAS 1.1 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies\n",
    "\n",
    "If not already done, make sure to install OneQA with `notebooks` extras before getting started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# If you want CUDA 11 uncomment and run this (for CUDA 10 or CPU you can ignore this line).\n",
    "#! pip install 'torch~=1.11.0' --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "\n",
    "# Uncomment to install OneQA from source (pypi package pending).\n",
    "# The path should be the project root (e.g. '.' below).\n",
    "#! pip install .[notebooks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "\n",
    "We start by setting some parameters to configure the process.  Note that depending on the GPU being used you may need to tune the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This needs to be filled in.\n",
    "# output_dir = 'FILL_ME_IN'        # Save the results here.  Will overwrite if directory already exists.\n",
    "output_dir = 'tmp'\n",
    "# Optional parameters (feel free to leave as default).\n",
    "model_name = 'xlm-roberta-base'  # Set this to select the LM.  Since this is a multi-lingual dataset, we use the XLM-Roberta model.\n",
    "cache_dir = None                 # Set this if you have a cache directory for transformers.  Alternatively set the HF_HOME env var.\n",
    "train_batch_size = 8             # Set this to change the number of features per batch during training.\n",
    "eval_batch_size = 8              # Set this to change the number of features per batch during evaluation.\n",
    "gradient_accumulation_steps = 8  # Set this to effectively increase training batch size.\n",
    "max_train_samples = 100          # Set this to use a subset of the training data (or None for all).\n",
    "max_eval_samples = 20            # Set this to use a subset of the evaluation data (or None for all).\n",
    "num_train_epochs = 1             # Set this to change the number of training epochs.\n",
    "fp16 = False                     # Set this to true to enable fp16 (hardware support required).\n",
    "num_examples_to_show = 10        # Set this to change the number of random train examples (and their features) to show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from transformers.trainer_utils import set_seed\n",
    "\n",
    "seed = 42\n",
    "set_seed(seed)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=train_batch_size,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    evaluation_strategy='no',\n",
    "    learning_rate=4e-05,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.1,\n",
    "    save_steps=50000,\n",
    "    fp16=fp16,\n",
    "    seed=seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Model\n",
    "\n",
    "Here we load the model and tokenizer based on the model_name parameter set above.  We use a model with an extractive QA task head which we will later fine-tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaModelForDownstreamTasks were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['task_heads.qa_head.qa_outputs.bias', 'task_heads.qa_head.classifier.dense.bias', 'task_heads.qa_head.classifier.out_proj.bias', 'task_heads.qa_head.qa_outputs.weight', 'task_heads.qa_head.classifier.dense.weight', 'task_heads.qa_head.classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLMRobertaModelForDownstreamTasks(\n",
      "  (roberta): XLMRobertaModel(\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): RobertaEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): RobertaPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (lm_head): RobertaLMHead(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (decoder): Linear(in_features=768, out_features=250002, bias=True)\n",
      "  )\n",
      "  (task_heads): ModuleDict(\n",
      "    (qa_head): ExtractiveQAHead(\n",
      "      (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
      "      (classifier): RobertaClassificationHead(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=5, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoTokenizer\n",
    "from oneqa.mrc.models.heads.extractive import EXTRACTIVE_HEAD\n",
    "from oneqa.mrc.models.task_model import ModelForDownstreamTasks\n",
    "\n",
    "from oneqa.mrc.trainers.mrc import MRCTrainer\n",
    "\n",
    "task_heads = EXTRACTIVE_HEAD\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir=cache_dir,\n",
    "    use_fast=True,\n",
    "    config=config,\n",
    ")\n",
    "model = ModelForDownstreamTasks.from_config(\n",
    "    config,\n",
    "    model_name,\n",
    "    task_heads=task_heads,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "model.set_task_head(next(iter(task_heads)))\n",
    "\n",
    "print(model)  # Examine the model structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "\n",
    "Here we load the SQuAD 1.1 dataset using Huggingface's datasets library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/u/mabornea/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0c86e5c71634a78bb106b8a3b05b13e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 100 train examples.\n",
      "Using 20 eval examples.\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import random\n",
    "\n",
    "raw_datasets = datasets.load_dataset(\n",
    "    'squad',\n",
    "    'plain_text',\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "\n",
    "train_examples = raw_datasets[\"train\"]\n",
    "max_train_samples = max_train_samples\n",
    "if max_train_samples is not None:\n",
    "    # We will select sample from whole data if argument is specified\n",
    "    train_examples = train_examples.select(range(max_train_samples))\n",
    "\n",
    "print(f\"Using {train_examples.num_rows} train examples.\")\n",
    "\n",
    "eval_examples = raw_datasets[\"validation\"]\n",
    "max_eval_samples = max_eval_samples\n",
    "if max_eval_samples is not None:\n",
    "    # We will select sample from whole data if argument is specified\n",
    "    random_idxs = random.sample(range(len(eval_examples)), max_eval_samples)\n",
    "    eval_examples = eval_examples.select(random_idxs)\n",
    "\n",
    "print(f\"Using {eval_examples.num_rows} eval examples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "Here we preprocess the data to create features which can be given to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /u/mabornea/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453/cache-beec2b718128c871.arrow\n",
      "Loading cached processed dataset at /u/mabornea/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453/cache-6ea01577bc09ec02.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing produced 100 train features from 100 examples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7346e7238c4840a6930c00056150c2f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b5d204e9f84da394a7d3e6da310059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on eval dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing produced 20 eval features from 20 examples.\n"
     ]
    }
   ],
   "source": [
    "from oneqa.mrc.processors.preprocessors.squad import SQUADPreprocessor\n",
    "\n",
    "preprocessor = SQUADPreprocessor(\n",
    "    stride=128,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Train Feature Creation\n",
    "with training_args.main_process_first(desc=\"train dataset map pre-processing\"):\n",
    "    train_examples, train_dataset = preprocessor.process_train(train_examples)\n",
    "\n",
    "print(f\"Preprocessing produced {train_dataset.num_rows} train features from {train_examples.num_rows} examples.\")\n",
    "\n",
    "# Validation Feature Creation\n",
    "with training_args.main_process_first(desc=\"validation dataset map pre-processing\"):\n",
    "    eval_examples, eval_dataset = preprocessor.process_eval(eval_examples)\n",
    "\n",
    "print(f\"Preprocessing produced {eval_dataset.num_rows} eval features from {eval_examples.num_rows} examples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import ClassLabel, Sequence\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Based on https://github.com/huggingface/notebooks/blob/main/examples/question_answering.ipynb\n",
    "def show_elements(dataset):\n",
    "    df = pd.DataFrame(dataset)\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c0100feafe3436283b1d6574fd8c190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>example_id</th>\n",
       "      <th>target</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>As of 2012[update] research continued in many fields. The university president, John Jenkins, described his hope that Notre Dame would become \"one of the pre–eminent research institutions in the world\" in his inaugural address. The university has many multi-disciplinary institutes devoted to research in varying fields, including the Medieval Institute, the Kellogg Institute for International Studies, the Kroc Institute for International Peace studies, and the Center for Social Concerns. Recen...</td>\n",
       "      <td>In what year did Notre Dame begin to host the Global Adaptation Index?</td>\n",
       "      <td>5733b5344776f419006610e0</td>\n",
       "      <td>{'end_positions': [757], 'passage_indices': [0], 'start_positions': [753], 'yes_no_answer': ['NONE']}</td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>The university first offered graduate degrees, in the form of a Master of Arts (MA), in the 1854–1855 academic year. The program expanded to include Master of Laws (LL.M.) and Master of Civil Engineering in its early stages of growth, before a formal graduate school education was developed with a thesis not required to receive the degrees. This changed in 1924 with formal requirements developed for graduate degrees, including offering Doctorate (PhD) degrees. Today each of the five colleges o...</td>\n",
       "      <td>What type of degree is an M.Div.?</td>\n",
       "      <td>5733a7bd4776f41900660f6c</td>\n",
       "      <td>{'end_positions': [642], 'passage_indices': [0], 'start_positions': [624], 'yes_no_answer': ['NONE']}</td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>This Main Building, and the library collection, was entirely destroyed by a fire in April 1879, and the school closed immediately and students were sent home. The university founder, Fr. Sorin and the president at the time, the Rev. William Corby, immediately planned for the rebuilding of the structure that had housed virtually the entire University. Construction was started on the 17th of May and by the incredible zeal of administrator and workers the building was completed before the fall s...</td>\n",
       "      <td>On what date was the rebuilding of The Main Building begun at Notre Dame after the fire that claimed the previous?</td>\n",
       "      <td>57338653d058e614000b5c83</td>\n",
       "      <td>{'end_positions': [396], 'passage_indices': [0], 'start_positions': [385], 'yes_no_answer': ['NONE']}</td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>The university is affiliated with the Congregation of Holy Cross (Latin: Congregatio a Sancta Cruce, abbreviated postnominals: \"CSC\"). While religious affiliation is not a criterion for admission, more than 93% of students identify as Christian, with over 80% of the total being Catholic. Collectively, Catholic Mass is celebrated over 100 times per week on campus, and a large campus ministry program provides for the faith needs of the community. There are multitudes of religious statues and ar...</td>\n",
       "      <td>What is Congregation of Holy Cross in Latin?</td>\n",
       "      <td>5733b7f74776f4190066112d</td>\n",
       "      <td>{'end_positions': [99], 'passage_indices': [0], 'start_positions': [73], 'yes_no_answer': ['NONE']}</td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>This Main Building, and the library collection, was entirely destroyed by a fire in April 1879, and the school closed immediately and students were sent home. The university founder, Fr. Sorin and the president at the time, the Rev. William Corby, immediately planned for the rebuilding of the structure that had housed virtually the entire University. Construction was started on the 17th of May and by the incredible zeal of administrator and workers the building was completed before the fall s...</td>\n",
       "      <td>In what year was the Main Building at Notre Dame razed in a fire?</td>\n",
       "      <td>57338653d058e614000b5c81</td>\n",
       "      <td>{'end_positions': [94], 'passage_indices': [0], 'start_positions': [90], 'yes_no_answer': ['NONE']}</td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>As of 2012[update] research continued in many fields. The university president, John Jenkins, described his hope that Notre Dame would become \"one of the pre–eminent research institutions in the world\" in his inaugural address. The university has many multi-disciplinary institutes devoted to research in varying fields, including the Medieval Institute, the Kellogg Institute for International Studies, the Kroc Institute for International Peace studies, and the Center for Social Concerns. Recen...</td>\n",
       "      <td>The Kellogg Institute for International Studies is part of which university?</td>\n",
       "      <td>5733b5344776f419006610de</td>\n",
       "      <td>{'end_positions': [128], 'passage_indices': [0], 'start_positions': [118], 'yes_no_answer': ['NONE']}</td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Father Joseph Carrier, C.S.C. was Director of the Science Museum and the Library and Professor of Chemistry and Physics until 1874. Carrier taught that scientific research and its promise for progress were not antagonistic to the ideals of intellectual and moral culture endorsed by the Church. One of Carrier's students was Father John Augustine Zahm (1851–1921) who was made Professor and Co-Director of the Science Department at age 23 and by 1900 was a nationally prominent scientist and natur...</td>\n",
       "      <td>What professorship did Father Josh Carrier hold at Notre Dame?</td>\n",
       "      <td>5733b0fb4776f41900661042</td>\n",
       "      <td>{'end_positions': [119], 'passage_indices': [0], 'start_positions': [85], 'yes_no_answer': ['NONE']}</td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>The university first offered graduate degrees, in the form of a Master of Arts (MA), in the 1854–1855 academic year. The program expanded to include Master of Laws (LL.M.) and Master of Civil Engineering in its early stages of growth, before a formal graduate school education was developed with a thesis not required to receive the degrees. This changed in 1924 with formal requirements developed for graduate degrees, including offering Doctorate (PhD) degrees. Today each of the five colleges o...</td>\n",
       "      <td>Which department at Notre Dame is the only one to not offer a PhD program?</td>\n",
       "      <td>5733a7bd4776f41900660f6d</td>\n",
       "      <td>{'end_positions': [795], 'passage_indices': [0], 'start_positions': [757], 'yes_no_answer': ['NONE']}</td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>In 1882, Albert Zahm (John Zahm's brother) built an early wind tunnel used to compare lift to drag of aeronautical models. Around 1899, Professor Jerome Green became the first American to send a wireless message. In 1931, Father Julius Nieuwland performed early work on basic reactions that was used to create neoprene. Study of nuclear physics at the university began with the building of a nuclear accelerator in 1936, and continues now partly through a partnership in the Joint Institute for Nu...</td>\n",
       "      <td>Which individual worked on projects at Notre Dame that eventually created neoprene?</td>\n",
       "      <td>5733b1da4776f4190066106b</td>\n",
       "      <td>{'end_positions': [245], 'passage_indices': [0], 'start_positions': [222], 'yes_no_answer': ['NONE']}</td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>In 2014 the Notre Dame student body consisted of 12,179 students, with 8,448 undergraduates, 2,138 graduate and professional and 1,593 professional (Law, M.Div., Business, M.Ed.) students. Around 21–24% of students are children of alumni, and although 37% of students come from the Midwestern United States, the student body represents all 50 states and 100 countries. As of March 2007[update] The Princeton Review ranked the school as the fifth highest 'dream school' for parents to send their ch...</td>\n",
       "      <td>How many teams participate in the Notre Dame Bookstore Basketball tournament?</td>\n",
       "      <td>5733b5df4776f41900661107</td>\n",
       "      <td>{'end_positions': [1454], 'passage_indices': [0], 'start_positions': [1446], 'yes_no_answer': ['NONE']}</td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def trim_document(example, max_len=500):\n",
    "    example['context'] = example['context'][0]\n",
    "    doc_len = len(example['context'])\n",
    "    if doc_len > max_len:\n",
    "        example['context'] = f\"{example['context'][:max_len - 3]}...\"        \n",
    "    return example\n",
    "\n",
    "random_idxs = random.sample(range(len(train_examples)), num_examples_to_show)\n",
    "random_train_examples = train_examples.select(random_idxs).remove_columns(['passage_candidates'])\n",
    "random_train_examples = random_train_examples.map(trim_document)\n",
    "\n",
    "show_elements(random_train_examples)  # Show random train examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24815f8f3798499390630be0e47050a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c39be1440cf54973b1acc7654211ce83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>example_idx</th>\n",
       "      <th>start_positions</th>\n",
       "      <th>end_positions</th>\n",
       "      <th>target_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733a7bd4776f41900660f6c</td>\n",
       "      <td>[0, 4865, 10644, 111, 79385, 83, 142, 276, 5, 192576, 5, 32, 2, 2, 581, 152363, 5117, 122399, 150180, 79385, 7, 4, 23, 70, 3173, 111, 10, 18897, 111, 64624, 15, 8218, 247, 23, 70, 543, 12338, 132869, 11663, 108858, 6602, 5, 581, 1528, 71062, 297, 47, 26698, 18897, 111, 36293, 7, 15, 23708, 5, 594, 5, 16, 136, 18897, 111, 18543, 123470, 23, 6863, 39395, 36541, 7, 111, 75678, 4, 8108, 10, 23113, 150180, 10696, 53019, 509, 126809, 678, 10, 159688, 959, 56065, 47, 53299, 70, 79385, 7, 5, 3293, 98816, 23, 58410, 678, 23113, 96679, 126809, 100, 150180, ...]</td>\n",
       "      <td>25</td>\n",
       "      <td>145</td>\n",
       "      <td>148</td>\n",
       "      <td>SPAN_ANSWER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5733a7bd4776f41900660f6d</td>\n",
       "      <td>[0, 130078, 130625, 99, 52151, 67388, 83, 70, 4734, 1632, 47, 959, 18645, 10, 101862, 1528, 32, 2, 2, 581, 152363, 5117, 122399, 150180, 79385, 7, 4, 23, 70, 3173, 111, 10, 18897, 111, 64624, 15, 8218, 247, 23, 70, 543, 12338, 132869, 11663, 108858, 6602, 5, 581, 1528, 71062, 297, 47, 26698, 18897, 111, 36293, 7, 15, 23708, 5, 594, 5, 16, 136, 18897, 111, 18543, 123470, 23, 6863, 39395, 36541, 7, 111, 75678, 4, 8108, 10, 23113, 150180, 10696, 53019, 509, 126809, 678, 10, 159688, 959, 56065, 47, 53299, 70, 79385, 7, 5, 3293, 98816, 23, 58410, 678, ...]</td>\n",
       "      <td>28</td>\n",
       "      <td>182</td>\n",
       "      <td>188</td>\n",
       "      <td>SPAN_ANSWER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5733b0fb4776f41900661042</td>\n",
       "      <td>[0, 4865, 16030, 16070, 6777, 160960, 146393, 3980, 25388, 16401, 99, 52151, 67388, 32, 2, 2, 160960, 33876, 3980, 25388, 4, 313, 5, 294, 5, 441, 5, 509, 31068, 111, 70, 28745, 25946, 136, 70, 103835, 136, 43552, 111, 83230, 38904, 136, 165712, 7, 24189, 186868, 5, 3980, 25388, 189924, 450, 57456, 25188, 136, 6863, 103036, 100, 42658, 3542, 959, 63212, 6126, 48242, 47, 70, 6397, 7, 111, 91768, 289, 136, 14392, 29394, 22, 31004, 297, 390, 70, 84084, 5, 6561, 111, 3980, 25388, 25, 7, 25921, 509, 160960, 4939, 104734, 13, 825, 18337, 7435, 11703, 74668, 69072, 2750, 509, ...]</td>\n",
       "      <td>53</td>\n",
       "      <td>37</td>\n",
       "      <td>43</td>\n",
       "      <td>SPAN_ANSWER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5733b1da4776f4190066106b</td>\n",
       "      <td>[0, 130078, 11651, 79786, 98, 77635, 99, 52151, 67388, 450, 155605, 75935, 16169, 26344, 13, 32, 2, 2, 360, 156999, 4, 24748, 825, 18337, 15, 98385, 825, 18337, 25, 7, 82953, 16, 88303, 142, 39395, 32382, 80208, 11814, 47, 69101, 60520, 47, 24911, 111, 37511, 10792, 70760, 115774, 5, 62, 67688, 122815, 4, 43552, 27971, 13450, 15497, 100512, 70, 5117, 15672, 47, 25379, 10, 135051, 26008, 5, 360, 66426, 4, 160960, 109112, 128365, 1760, 51339, 297, 39395, 4488, 98, 62822, 132539, 7, 450, 509, 11814, 47, 28282, 16169, 26344, 13, 5, 148027, 111, 72249, 6, 34053, 27744, 7, 99, 70, ...]</td>\n",
       "      <td>57</td>\n",
       "      <td>70</td>\n",
       "      <td>73</td>\n",
       "      <td>SPAN_ANSWER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5733b5344776f419006610de</td>\n",
       "      <td>[0, 581, 23203, 4867, 177, 43975, 100, 8357, 132268, 83, 2831, 111, 3129, 152363, 32, 2, 2, 1301, 111, 1324, 1065, 117008, 268, 25188, 136475, 23, 5941, 44457, 7, 5, 581, 152363, 13918, 4, 4939, 234339, 4, 151552, 1919, 15673, 450, 52151, 67388, 2806, 24209, 44, 3630, 111, 70, 479, 1104, 13, 7732, 18, 25188, 38016, 7, 23, 70, 8999, 58, 23, 1919, 33428, 141, 29823, 5, 581, 152363, 1556, 5941, 6024, 9, 141223, 6635, 32872, 90, 30396, 3674, 47, 25188, 23, 285, 38543, 44457, 7, 4, 26719, 70, 11214, 13, 1405, 43975, 4, 70, 23203, 4867, 177, 43975, 100, ...]</td>\n",
       "      <td>69</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>SPAN_ANSWER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5733b5344776f419006610e0</td>\n",
       "      <td>[0, 360, 2367, 6602, 6777, 52151, 67388, 9842, 47, 27980, 70, 13453, 91903, 2320, 31471, 32, 2, 2, 1301, 111, 1324, 1065, 117008, 268, 25188, 136475, 23, 5941, 44457, 7, 5, 581, 152363, 13918, 4, 4939, 234339, 4, 151552, 1919, 15673, 450, 52151, 67388, 2806, 24209, 44, 3630, 111, 70, 479, 1104, 13, 7732, 18, 25188, 38016, 7, 23, 70, 8999, 58, 23, 1919, 33428, 141, 29823, 5, 581, 152363, 1556, 5941, 6024, 9, 141223, 6635, 32872, 90, 30396, 3674, 47, 25188, 23, 285, 38543, 44457, 7, 4, 26719, 70, 11214, 13, 1405, 43975, 4, 70, 23203, 4867, 177, 43975, ...]</td>\n",
       "      <td>71</td>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "      <td>SPAN_ANSWER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5733b5df4776f41900661107</td>\n",
       "      <td>[0, 11249, 5941, 87199, 42938, 13, 23, 70, 52151, 67388, 83266, 7535, 234333, 233547, 32, 2, 2, 360, 1049, 70, 52151, 67388, 9836, 14361, 35060, 71, 111, 427, 4, 156918, 25921, 4, 678, 382, 4, 165116, 1379, 88610, 63614, 4, 116, 4, 141535, 150180, 136, 23182, 136, 10285, 11591, 23182, 15, 2729, 434, 4, 276, 5, 192576, 5, 4, 14249, 4, 276, 5, 69489, 5, 16, 25921, 5, 62, 67688, 952, 1104, 304, 11267, 111, 25921, 621, 20020, 111, 228140, 4, 136, 102971, 138, 14427, 111, 25921, 1380, 1295, 70, 23166, 1177, 48850, 14098, 46684, 4, 70, 9836, 14361, 33636, ...]</td>\n",
       "      <td>75</td>\n",
       "      <td>350</td>\n",
       "      <td>351</td>\n",
       "      <td>SPAN_ANSWER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5733b7f74776f4190066112d</td>\n",
       "      <td>[0, 4865, 83, 237626, 19, 111, 152239, 47832, 23, 42845, 32, 2, 2, 581, 152363, 83, 148272, 71, 678, 70, 237626, 19, 111, 152239, 47832, 15, 2729, 2311, 12, 237626, 10, 192437, 41649, 329, 4, 1563, 105160, 14, 27686, 1305, 175574, 8080, 12, 44, 441, 14495, 51029, 51404, 167821, 261, 67666, 2320, 83, 959, 10, 166220, 19, 100, 606, 21150, 4, 1286, 3501, 483, 11587, 111, 25921, 135812, 237, 14949, 4, 678, 645, 20668, 111, 70, 3622, 8035, 129574, 5, 138521, 5844, 538, 4, 129574, 74227, 83, 176016, 71, 645, 805, 20028, 117, 5895, 98, 78132, 4, 136, 10, 21334, ...]</td>\n",
       "      <td>83</td>\n",
       "      <td>29</td>\n",
       "      <td>33</td>\n",
       "      <td>SPAN_ANSWER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>57338653d058e614000b5c81</td>\n",
       "      <td>[0, 360, 2367, 6602, 509, 70, 12321, 104919, 99, 52151, 67388, 1954, 297, 23, 10, 11476, 32, 2, 2, 3293, 12321, 104919, 4, 136, 70, 35773, 1294, 42486, 4, 509, 167969, 163684, 297, 390, 10, 11476, 23, 7071, 176447, 4, 136, 70, 10696, 155738, 109312, 136, 25921, 3542, 9325, 5368, 5, 581, 152363, 14037, 56, 4, 21894, 5, 13965, 73, 136, 70, 13918, 99, 70, 1733, 4, 70, 80893, 5, 25031, 5631, 1272, 4, 109312, 203251, 100, 70, 456, 146049, 111, 70, 45646, 450, 1902, 18276, 71, 20513, 538, 70, 64194, 12535, 5, 195769, 509, 26859, 98, 70, 729, 927, ...]</td>\n",
       "      <td>89</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>SPAN_ANSWER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>57338653d058e614000b5c83</td>\n",
       "      <td>[0, 2161, 2367, 5622, 509, 70, 456, 146049, 111, 581, 12321, 104919, 186, 6967, 99, 52151, 67388, 7103, 70, 11476, 450, 63043, 297, 70, 96362, 32, 2, 2, 3293, 12321, 104919, 4, 136, 70, 35773, 1294, 42486, 4, 509, 167969, 163684, 297, 390, 10, 11476, 23, 7071, 176447, 4, 136, 70, 10696, 155738, 109312, 136, 25921, 3542, 9325, 5368, 5, 581, 152363, 14037, 56, 4, 21894, 5, 13965, 73, 136, 70, 13918, 99, 70, 1733, 4, 70, 80893, 5, 25031, 5631, 1272, 4, 109312, 203251, 100, 70, 456, 146049, 111, 70, 45646, 450, 1902, 18276, 71, 20513, 538, 70, 64194, ...]</td>\n",
       "      <td>91</td>\n",
       "      <td>107</td>\n",
       "      <td>110</td>\n",
       "      <td>SPAN_ANSWER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from oneqa.mrc.data_models.target_type import TargetType\n",
    "\n",
    "def target_type_as_str(feature):\n",
    "    feature['target_type'] = TargetType(feature['target_type']).name\n",
    "    return feature\n",
    "\n",
    "random_train_dataset = train_dataset.filter(lambda feature: feature['example_idx'] in random_idxs).remove_columns(['attention_mask', 'offset_mapping'])\n",
    "show_elements(random_train_dataset.map(target_type_as_str))  # Show random train features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning\n",
    "\n",
    "Here we fine-tune the model on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dccstor/mabornea1/miniconda3/envs/squad-framework/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 100\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 8\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to tmp\n",
      "Configuration saved in tmp/config.json\n",
      "Model weights saved in tmp/pytorch_model.bin\n",
      "tokenizer config file saved in tmp/tokenizer_config.json\n",
      "Special tokens file saved in tmp/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.62\n",
      "  total_flos               =    10421GF\n",
      "  train_loss               =     4.4133\n",
      "  train_runtime            = 0:00:31.81\n",
      "  train_samples            =        100\n",
      "  train_samples_per_second =      3.143\n",
      "  train_steps_per_second   =      0.031\n"
     ]
    }
   ],
   "source": [
    "from operator import attrgetter\n",
    "import datasets\n",
    "from transformers import DataCollatorWithPadding\n",
    "from oneqa.mrc.data_models.eval_prediction_with_processing import EvalPredictionWithProcessing\n",
    "from oneqa.mrc.processors.postprocessors.squad import SQUADPostProcessor\n",
    "from oneqa.mrc.processors.postprocessors.scorers import SupportedSpanScorers\n",
    "\n",
    "# If using mixed precision we pad for efficient hardware acceleration\n",
    "using_mixed_precision = any(attrgetter('fp16', 'bf16')(training_args))\n",
    "data_collator = DataCollatorWithPadding(tokenizer, pad_to_multiple_of=64 if using_mixed_precision else None)\n",
    "\n",
    "# noinspection PyProtectedMember\n",
    "postprocessor = SQUADPostProcessor(\n",
    "    k=3,\n",
    "    n_best_size=20,\n",
    "    max_answer_length=30,\n",
    "    scorer_type=SupportedSpanScorers.WEIGHTED_SUM_TARGET_TYPE_AND_SCORE_DIFF,\n",
    "    single_context_multiple_passages=preprocessor._single_context_multiple_passages,\n",
    ")\n",
    "\n",
    "def compute_metrics(p: EvalPredictionWithProcessing):\n",
    "    eval_metrics = datasets.load_metric(\"squad\")\n",
    "    return eval_metrics.compute(predictions=p.processed_predictions, references=p.label_ids)\n",
    "\n",
    "trainer = MRCTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset if training_args.do_train else None,\n",
    "    eval_dataset=eval_dataset if training_args.do_eval else None,\n",
    "    eval_examples=eval_examples if training_args.do_eval else None,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    post_process_function=postprocessor.process_references_and_predictions,  # see QATrainer in Huggingface\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "train_result = trainer.train()\n",
    "trainer.save_model()  # Saves the tokenizer too for easy upload\n",
    "\n",
    "metrics = train_result.metrics\n",
    "max_train_samples = max_train_samples or len(train_dataset)\n",
    "metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n",
    "\n",
    "trainer.log_metrics(\"train\", metrics)\n",
    "trainer.save_metrics(\"train\", metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Here we evaluate the model on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 540.89it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 4289.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch            =   0.62\n",
      "  eval_exact_match =    0.0\n",
      "  eval_f1          = 3.8277\n",
      "  eval_samples     =     20\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate()\n",
    "\n",
    "max_eval_samples = max_eval_samples or len(eval_dataset)\n",
    "metrics[\"eval_samples\"] = min(max_eval_samples, len(eval_dataset))\n",
    "\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions\n",
    "\n",
    "Here we examine the model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': '573786b51c4567190057448d',\n",
      "  'prediction_text': 'radius () of the Earth to the gravitational accelerat'},\n",
      " {'id': '56e1ddfce3433e14004231d8',\n",
      "  'prediction_text': 'question of whether P equals NP is one'},\n",
      " {'id': '56bf48cc3aeaaa14008c95af',\n",
      "  'prediction_text': 'team to have worn white as the designated home team in '\n",
      "                     'the Super Bowl was the Pittsburgh Steel'},\n",
      " {'id': '5725c337271a42140099d164',\n",
      "  'prediction_text': 'cles fringed with tentilla (\"little tentacles\") that are '\n",
      "                     'covered with colloblasts, sticky cells that capture pre'},\n",
      " {'id': '5725e44238643c19005ace36', 'prediction_text': 'minutes. On one'},\n",
      " {'id': '571ccfbadd7acb1400e4c164',\n",
      "  'prediction_text': 'hydrogen and oxygen in the explosive ratio 2:1. Contra'},\n",
      " {'id': '56f827caa6d7ea1400e1743a', 'prediction_text': 'claring Luther an out'},\n",
      " {'id': '56e127bccd28a01900c6765f', 'prediction_text': 'e'},\n",
      " {'id': '572976183f37b31900478431',\n",
      "  'prediction_text': 'rose being exported out of the chloroplast (or more '\n",
      "                     'accurate'},\n",
      " {'id': '56e0f32d231d4119001ac4cb',\n",
      "  'prediction_text': \"ray image—predating, by a few weeks, Wilhelm Röntgen's \"\n",
      "                     'December 1895 announcement of the discovery of x-'},\n",
      " {'id': '5730005db2c2fd1400568707',\n",
      "  'prediction_text': 'wrote about contemporary issues and most importantly '\n",
      "                     'about Islam and Islamic law. Maududi founded the '\n",
      "                     'Jamaat-e-Islam'},\n",
      " {'id': '57273a465951b619008f86ff',\n",
      "  'prediction_text': 'differs from manufacturing in that manufacturing '\n",
      "                     'typically involves mass production of similar items '\n",
      "                     'without a designated purchaser, while construction '\n",
      "                     'typically takes place on location'},\n",
      " {'id': '56d71d150d65d2140019836f',\n",
      "  'prediction_text': 'Committee has vowed to be \"the most giving'},\n",
      " {'id': '56bebde53aeaaa14008c9338',\n",
      "  'prediction_text': 'Center in San Jose. Alongside the traditional media '\n",
      "                     'availabilities, the event featured an opening ce'},\n",
      " {'id': '56e10b6ee3433e1400422b25', 'prediction_text': 'prop'},\n",
      " {'id': '571c91c8dd7acb1400e4c10e',\n",
      "  'prediction_text': 'cule. Due to its energy content, O2 is used by complex '\n",
      "                     'forms of life'},\n",
      " {'id': '57265bdfdd62a815002e82a0',\n",
      "  'prediction_text': 'ury oriented sedans became popular again in the '\n",
      "                     'mid-1970s. The only full-'},\n",
      " {'id': '57287fec4b864d1900164a3d', 'prediction_text': 'hism, other religion'},\n",
      " {'id': '57308f6b8ab72b1400f9c581',\n",
      "  'prediction_text': 'ography relies on an essentializing discourse that '\n",
      "                     'represents neither the diversi'},\n",
      " {'id': '56bebbbf3aeaaa14008c9317',\n",
      "  'prediction_text': 'Bowl L. The use of Roman numer'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "with open(os.path.join(output_dir, 'eval_predictions_processed.json'), 'r') as f:\n",
    "    predictions = json.load(f)\n",
    "\n",
    "pprint(predictions)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4e4f4935d8d6e168f83b63f668693470d973fc5ae597a9aa001666a5d8c3ebbd"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 ('squad-framework')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
